{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoFbXojE1K7Q"
      },
      "outputs": [],
      "source": [
        "# Model architecture inspired by Z. Hameed and B. Garcia-Zapirain, \"Sentiment classification using a single-layered BiLSTM model\", IEEE Access, vol. 8, pp. 73992-74001, 2020.\n",
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "info = api.info()  # show info about available models/datasets\n",
        "w2v = api.load(\"word2vec-google-news-300\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY0fcLYU1mOl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import re\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Bidirectional, LSTM, Input, GlobalMaxPool1D, GlobalAveragePooling1D, concatenate\n",
        "\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "def process_text(document):\n",
        "     \n",
        "    # Remove extra white space from text\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "         \n",
        "    # Remove all the special characters from text\n",
        "    document = re.sub(r'\\W', ' ', str(document))\n",
        " \n",
        "    return document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "o8nUfUs_GAse",
        "outputId": "73ba5b80-11af-4dff-9fea-fde5d24e44e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Statement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joy</td>\n",
              "      <td>Thank you , Steven . I accept your advice .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>surprise</td>\n",
              "      <td>Oh my God, I can't believe I have two-two chil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Look, it's not that big of a deal, so Monica a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>anger</td>\n",
              "      <td>And I wanna know why?!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>joy</td>\n",
              "      <td>And, ah, you know, your fooling around with her.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Emotion                                          Statement\n",
              "0       joy       Thank you , Steven . I accept your advice . \n",
              "1  surprise  Oh my God, I can't believe I have two-two chil...\n",
              "2   neutral  Look, it's not that big of a deal, so Monica a...\n",
              "3     anger                            And I wanna know why?!!\n",
              "4       joy   And, ah, you know, your fooling around with her."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv('LOCAL_PATH_TO_DATASET')\n",
        "df = df[['Emotion','Statement']]\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Skvz-K3mGDcz",
        "outputId": "b9f945d1-d3ae-4876-b4ba-10d91adecd6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Statement</th>\n",
              "      <th>preprocessedStatement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joy</td>\n",
              "      <td>Thank you , Steven . I accept your advice .</td>\n",
              "      <td>Thank you   Steven   I accept your advice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>surprise</td>\n",
              "      <td>Oh my God, I can't believe I have two-two chil...</td>\n",
              "      <td>Oh my God  I can t believe I have two two chil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Look, it's not that big of a deal, so Monica a...</td>\n",
              "      <td>Look  it s not that big of a deal  so Monica a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>anger</td>\n",
              "      <td>And I wanna know why?!!</td>\n",
              "      <td>And I wanna know why</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>joy</td>\n",
              "      <td>And, ah, you know, your fooling around with her.</td>\n",
              "      <td>And  ah  you know  your fooling around with her</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Emotion  ...                              preprocessedStatement\n",
              "0       joy  ...       Thank you   Steven   I accept your advice   \n",
              "1  surprise  ...  Oh my God  I can t believe I have two two chil...\n",
              "2   neutral  ...  Look  it s not that big of a deal  so Monica a...\n",
              "3     anger  ...                            And I wanna know why   \n",
              "4       joy  ...   And  ah  you know  your fooling around with her \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "df['preprocessedStatement'] = df.Statement.apply(process_text)\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0bu6mIdGFi4"
      },
      "outputs": [],
      "source": [
        "max_length = df.preprocessedStatement.apply(lambda x: len(x.split())).max()\n",
        "\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(df['preprocessedStatement'] )\n",
        "vocab_size = len(t.word_index) + 1\n",
        "encoded_tweets = t.texts_to_sequences(df['preprocessedStatement'] )\n",
        "X = pad_sequences(encoded_tweets, maxlen=max_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slnsbECWGIP4"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in t.word_index.items():\n",
        "    try:\n",
        "      embedding_vector = w2v[word]\n",
        "    except KeyError:\n",
        "      pass\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WprDeSeSGNr6",
        "outputId": "80b979f7-a768-46fe-87a8-4ffff60aa417"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "# Encode labels in column 'Emotion'. \n",
        "df['Emotion'] = le.fit_transform(df['Emotion']) \n",
        "y = df.pop('Emotion')\n",
        "#print(y)\n",
        "y_new = tf.keras.utils.to_categorical(y, num_classes=7)\n",
        "print(y_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LJBBN6DZnPH",
        "outputId": "de5e4c47-e0b6-4677-ec4d-77528f4efa6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(le.inverse_transform([0,1,2,3,4,5,6]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABQJ0lPHaG6e",
        "outputId": "113df93c-d08f-4a40-e6f5-4202e371c153"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3    15193\n",
              "4     6436\n",
              "6     3459\n",
              "0     2629\n",
              "5     2152\n",
              "1      714\n",
              "2      532\n",
              "Name: Emotion, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZXnrTYsZeU8"
      },
      "outputs": [],
      "source": [
        "# 2 options to handle imbalanced dataset: class_weight or focal loss\n",
        "class_weight = {0: 6, 1: 22, 2: 30, 3: 1, 4: 2, 5: 7, 6: 5}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBDWGAkrGR4y"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y_new, test_size=0.05, stratify=y_new)\n",
        "\n",
        "x_val = x_train[:100]\n",
        "y_val = y_train[:100]\n",
        "x_train = x_train[100:]\n",
        "y_train = y_train[100:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So4LLj325wBd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import activations\n",
        "\n",
        "def focal_loss(gamma=2., alpha=4., from_logits=False):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax if from_logits is False.\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "        if from_logits:\n",
        "            y_pred = activations.softmax(y_pred)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "b2IVxlRYGTjQ",
        "outputId": "a7dda793-49d7-4225-b084-bb3c645c890c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0f57dc2776ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model_glove = Sequential()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'max_length' is not defined"
          ]
        }
      ],
      "source": [
        "callback = EarlyStopping(monitor='val_loss', patience=3)\n",
        "input_layer = Input(shape=(max_length), )\n",
        "x = Embedding(vocab_size, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
        "x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "x_a = GlobalMaxPool1D()(x)\n",
        "x_b = GlobalAveragePooling1D()(x)\n",
        "x = concatenate([x_a,x_b])\n",
        "x = Dense(64, activation=\"relu\")(x)\n",
        "x = Dense(7, activation='softmax')(x)\n",
        "model_w2v = Model(inputs=input_layer, outputs=x)\n",
        "#model_ft.compile(loss=focal_loss(alpha=1), optimizer='adam', metrics=['accuracy']) #use if you are using focal loss\n",
        "model_w2v.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #use if you are using class_weight\n",
        "model_w2v.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_w2v,show_shapes= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuS7CcajGX3J",
        "outputId": "9b9788da-01d7-4cda-b394-a61345be071a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "921/921 [==============================] - 80s 82ms/step - loss: 5.7351 - accuracy: 0.4416 - val_loss: 1.4754 - val_accuracy: 0.5300\n",
            "Epoch 2/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 4.9423 - accuracy: 0.5444 - val_loss: 1.4899 - val_accuracy: 0.5300\n",
            "Epoch 3/50\n",
            "921/921 [==============================] - 74s 81ms/step - loss: 4.5998 - accuracy: 0.5699 - val_loss: 1.7247 - val_accuracy: 0.5100\n",
            "Epoch 4/50\n",
            "921/921 [==============================] - 74s 81ms/step - loss: 4.2927 - accuracy: 0.5889 - val_loss: 1.5139 - val_accuracy: 0.5300\n",
            "Epoch 5/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 3.9992 - accuracy: 0.6022 - val_loss: 1.6021 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 3.6981 - accuracy: 0.6168 - val_loss: 1.5112 - val_accuracy: 0.5100\n",
            "Epoch 7/50\n",
            "921/921 [==============================] - 74s 81ms/step - loss: 3.4322 - accuracy: 0.6285 - val_loss: 1.6736 - val_accuracy: 0.4900\n",
            "Epoch 8/50\n",
            "921/921 [==============================] - 74s 80ms/step - loss: 3.1818 - accuracy: 0.6408 - val_loss: 1.4943 - val_accuracy: 0.5500\n",
            "Epoch 9/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 2.9696 - accuracy: 0.6548 - val_loss: 1.4984 - val_accuracy: 0.5200\n",
            "Epoch 10/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 2.7728 - accuracy: 0.6634 - val_loss: 1.5529 - val_accuracy: 0.5400\n",
            "Epoch 11/50\n",
            "921/921 [==============================] - 74s 81ms/step - loss: 2.6246 - accuracy: 0.6712 - val_loss: 1.4247 - val_accuracy: 0.5700\n",
            "Epoch 12/50\n",
            "921/921 [==============================] - 74s 81ms/step - loss: 2.5037 - accuracy: 0.6822 - val_loss: 1.5696 - val_accuracy: 0.4900\n",
            "Epoch 13/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 2.3773 - accuracy: 0.6905 - val_loss: 1.3653 - val_accuracy: 0.5700\n",
            "Epoch 14/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 2.2777 - accuracy: 0.7001 - val_loss: 1.4169 - val_accuracy: 0.5800\n",
            "Epoch 15/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 2.1839 - accuracy: 0.7063 - val_loss: 1.5012 - val_accuracy: 0.5700\n",
            "Epoch 16/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 2.0770 - accuracy: 0.7167 - val_loss: 1.3816 - val_accuracy: 0.5400\n",
            "Epoch 17/50\n",
            "921/921 [==============================] - 74s 81ms/step - loss: 1.9778 - accuracy: 0.7243 - val_loss: 1.4566 - val_accuracy: 0.5500\n",
            "Epoch 18/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.9268 - accuracy: 0.7303 - val_loss: 1.4823 - val_accuracy: 0.5700\n",
            "Epoch 19/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.8836 - accuracy: 0.7363 - val_loss: 1.4813 - val_accuracy: 0.6000\n",
            "Epoch 20/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.7670 - accuracy: 0.7438 - val_loss: 1.5413 - val_accuracy: 0.5100\n",
            "Epoch 21/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.7143 - accuracy: 0.7543 - val_loss: 1.5277 - val_accuracy: 0.5600\n",
            "Epoch 22/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.6530 - accuracy: 0.7564 - val_loss: 1.5191 - val_accuracy: 0.5800\n",
            "Epoch 23/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.5976 - accuracy: 0.7635 - val_loss: 1.5729 - val_accuracy: 0.5500\n",
            "Epoch 24/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.5874 - accuracy: 0.7667 - val_loss: 1.7154 - val_accuracy: 0.5200\n",
            "Epoch 25/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.5099 - accuracy: 0.7734 - val_loss: 1.6508 - val_accuracy: 0.5800\n",
            "Epoch 26/50\n",
            "921/921 [==============================] - 75s 82ms/step - loss: 1.4531 - accuracy: 0.7781 - val_loss: 1.6198 - val_accuracy: 0.6000\n",
            "Epoch 27/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.4202 - accuracy: 0.7848 - val_loss: 1.5209 - val_accuracy: 0.5600\n",
            "Epoch 28/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.3621 - accuracy: 0.7887 - val_loss: 1.5383 - val_accuracy: 0.5500\n",
            "Epoch 29/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.3422 - accuracy: 0.7935 - val_loss: 1.6110 - val_accuracy: 0.5600\n",
            "Epoch 30/50\n",
            "921/921 [==============================] - 75s 82ms/step - loss: 1.2922 - accuracy: 0.8017 - val_loss: 1.8557 - val_accuracy: 0.5200\n",
            "Epoch 31/50\n",
            "921/921 [==============================] - 75s 82ms/step - loss: 1.2519 - accuracy: 0.8067 - val_loss: 1.6169 - val_accuracy: 0.5700\n",
            "Epoch 32/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.2358 - accuracy: 0.8080 - val_loss: 1.6983 - val_accuracy: 0.6200\n",
            "Epoch 33/50\n",
            "921/921 [==============================] - 74s 81ms/step - loss: 1.2143 - accuracy: 0.8112 - val_loss: 1.6946 - val_accuracy: 0.5400\n",
            "Epoch 34/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.1641 - accuracy: 0.8194 - val_loss: 1.8457 - val_accuracy: 0.5700\n",
            "Epoch 35/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.1750 - accuracy: 0.8174 - val_loss: 1.6715 - val_accuracy: 0.5900\n",
            "Epoch 36/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.1258 - accuracy: 0.8245 - val_loss: 1.7248 - val_accuracy: 0.5900\n",
            "Epoch 37/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.1234 - accuracy: 0.8282 - val_loss: 1.8734 - val_accuracy: 0.5500\n",
            "Epoch 38/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.0716 - accuracy: 0.8320 - val_loss: 1.8553 - val_accuracy: 0.5800\n",
            "Epoch 39/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.0599 - accuracy: 0.8324 - val_loss: 1.9185 - val_accuracy: 0.5800\n",
            "Epoch 40/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.0645 - accuracy: 0.8355 - val_loss: 1.9155 - val_accuracy: 0.5600\n",
            "Epoch 41/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.0434 - accuracy: 0.8395 - val_loss: 1.6026 - val_accuracy: 0.6000\n",
            "Epoch 42/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 0.9783 - accuracy: 0.8459 - val_loss: 1.7761 - val_accuracy: 0.5900\n",
            "Epoch 43/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 1.0049 - accuracy: 0.8440 - val_loss: 1.9592 - val_accuracy: 0.5800\n",
            "Epoch 44/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 0.9706 - accuracy: 0.8462 - val_loss: 1.8134 - val_accuracy: 0.5800\n",
            "Epoch 45/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 0.9690 - accuracy: 0.8486 - val_loss: 1.9456 - val_accuracy: 0.5600\n",
            "Epoch 46/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 0.9118 - accuracy: 0.8564 - val_loss: 1.9454 - val_accuracy: 0.5500\n",
            "Epoch 47/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 0.9290 - accuracy: 0.8554 - val_loss: 1.9785 - val_accuracy: 0.5200\n",
            "Epoch 48/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 0.9124 - accuracy: 0.8596 - val_loss: 2.0966 - val_accuracy: 0.5100\n",
            "Epoch 49/50\n",
            "921/921 [==============================] - 75s 81ms/step - loss: 0.9418 - accuracy: 0.8561 - val_loss: 2.1293 - val_accuracy: 0.5700\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f14e04d6d50>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_w2v.fit(x_train, y_train, epochs = 50, validation_data=(x_val, y_val), callbacks=[callback], class_weight=class_weight) #insert class_weight=class_weight if using class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPtsUjcdGZN3"
      },
      "outputs": [],
      "source": [
        "y_pred = model_w2v.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZTB3wN2GcOg"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(y_pred, 1)\n",
        "y_test = np.argmax(y_test, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4H-Lf0yGfyh",
        "outputId": "a1321f56-f326-4f93-b6f0-8d61fa4c3dcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.34      0.32       131\n",
            "           1       0.25      0.39      0.31        36\n",
            "           2       0.03      0.04      0.04        26\n",
            "           3       0.85      0.77      0.81       760\n",
            "           4       0.50      0.51      0.50       322\n",
            "           5       0.40      0.44      0.42       108\n",
            "           6       0.53      0.55      0.54       173\n",
            "\n",
            "    accuracy                           0.61      1556\n",
            "   macro avg       0.41      0.43      0.42      1556\n",
            "weighted avg       0.64      0.61      0.62      1556\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BiLSTM-W2V.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
