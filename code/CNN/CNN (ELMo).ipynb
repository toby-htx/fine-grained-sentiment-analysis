{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkvQREjsc-rr",
        "outputId": "87c3f14e-7b74-4fc1-e1cd-616b9f2e5563"
      },
      "outputs": [],
      "source": [
        "#Model architecture inspired by Y. Kim, \"Convolutional Neural Networks for Sentence Classification\", 2014\n",
        "!pip install tensorflow==1.15\n",
        "!pip install tensorflow_hub>=0.6.0\n",
        "!pip3 install tensorflow_text==1.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOlYzjJEc_-_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Input, Conv1D, GlobalMaxPool1D, Flatten\n",
        "from tensorflow.keras.layers import Lambda\n",
        "\n",
        "def process_text(document):\n",
        "     \n",
        "    # Remove extra white space from text\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "         \n",
        "    # Remove all the special characters from text\n",
        "    document = re.sub(r'\\W', ' ', str(document))\n",
        " \n",
        "    # Converting to Lowercase\n",
        "    document = document.lower()\n",
        " \n",
        "    # Word tokenization       \n",
        "    tokens = document.split()\n",
        "\n",
        "    tokens = [word for word in tokens if len(word) > 2]\n",
        " \n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qpBuoLGodpJY",
        "outputId": "24839c41-e255-43bd-cbaa-5275db8f273e"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('LOCAL_PATH_TO_DATASET')\n",
        "df = df[['Emotion','Statement']]\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "TooB-SlmRDhg",
        "outputId": "0bb2d83e-0a7f-4c89-ab8f-6f373758ac53"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "nltk.download('stopwords')\n",
        "# For sentence tokenization\n",
        "#nltk.download('punkt')\n",
        "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "nltk.download('wordnet')\n",
        "df['preprocessedStatement'] = df.Statement.apply(process_text)\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxvzLNj3TVyv"
      },
      "outputs": [],
      "source": [
        "max_length = df.preprocessedStatement.apply(lambda x: len(x)).max()\n",
        "\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(df['preprocessedStatement'] )\n",
        "vocab_size = len(t.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmCY69G8TWgX"
      },
      "outputs": [],
      "source": [
        "new_X = []\n",
        "for seq in df['preprocessedStatement']:\n",
        "    new_seq = []\n",
        "    for i in range(max_length):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(\"PADword\")\n",
        "    new_X.append(new_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfgEWJ7iTcSz",
        "outputId": "ea536df7-055a-444b-bc7d-47b5d40026e2"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "# Encode labels in column 'Emotion'. \n",
        "df['Emotion'] = le.fit_transform(df['Emotion']) \n",
        "y = df.pop('Emotion')\n",
        "y_new = tf.keras.utils.to_categorical(y, num_classes=7)\n",
        "print(y_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWTFcvCbTeVP"
      },
      "outputs": [],
      "source": [
        "new_X_df = pd.DataFrame(new_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeAKMoY2VlQX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(new_X_df, y_new, test_size=0.04, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7UGnneIVmLw"
      },
      "outputs": [],
      "source": [
        "#for meld-dd 64\n",
        "x_val, y_val = x_train[:174], y_train[:174] \n",
        "x_train, y_train = x_train[174:], y_train[174:]\n",
        "x_val, y_val = x_val[:128], y_val[:128] \n",
        "x_test, y_test = x_test[:1216], y_test[:1216]\n",
        "\n",
        "# #for isear 32\n",
        "# x_val, y_val = x_train[:143], y_train[:143] \n",
        "# x_train, y_train = x_train[143:], y_train[143:]\n",
        "# x_val, y_val = x_val[:128], y_val[:128] \n",
        "# x_test, y_test = x_test[:288], y_test[:288]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8UknDYcV3WD"
      },
      "outputs": [],
      "source": [
        "batch_size = 64 #32 for Isear, 64 for Meld-dd\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "\n",
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCkA0PRoV6cf"
      },
      "outputs": [],
      "source": [
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(inputs={\n",
        "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
        "                            \"sequence_len\": tf.constant(batch_size*[max_length])\n",
        "                      },\n",
        "                      signature=\"tokens\",\n",
        "                      as_dict=True)[\"elmo\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtqdZIdEV6mI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import activations\n",
        "\n",
        "def focal_loss(gamma=2., alpha=4.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGSo36F5WNu1",
        "outputId": "e462dc77-8db3-4c92-d1a8-41709decdc39"
      },
      "outputs": [],
      "source": [
        "callback = EarlyStopping(monitor='val_loss', patience=3)\n",
        "input_layer = Input(shape=(max_length, ), batch_size = batch_size, dtype=tf.string) \n",
        "embedding = Lambda(ElmoEmbedding, output_shape=(max_length, 1024))(input_layer)\n",
        "x = Conv1D(128, 5, activation='relu')(embedding)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation=\"relu\")(x) \n",
        "x = Dense(7, activation='softmax')(x)\n",
        "model_elmo = Model(inputs=input_layer, outputs=x)\n",
        "model_elmo.compile(loss=focal_loss(alpha=1), optimizer='adam', metrics=['accuracy']) #Alternative: tf.keras.metrics.Recall() as metric\n",
        "model_elmo.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_elmo,show_shapes= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0BHYr8-Y9Cl",
        "outputId": "8bd4ffa5-65b7-45ff-cced-0a774897a3ab"
      },
      "outputs": [],
      "source": [
        "model_elmo.fit(x_train, y_train, epochs = 10, callbacks=[callback], validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kaB--vZho7-"
      },
      "outputs": [],
      "source": [
        "y_pred = model_elmo.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSfZLHtjhsGL"
      },
      "outputs": [],
      "source": [
        "y_pred_clean = np.argmax(y_pred, 1)\n",
        "y_test_clean = np.argmax(y_test, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQQ9CvNkht7z"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test_clean, y_pred_clean))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CNN-Elmo-True.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
