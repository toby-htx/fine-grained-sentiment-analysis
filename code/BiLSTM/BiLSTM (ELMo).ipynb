{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z4hVYJqdM2p",
        "outputId": "add288f7-26fd-415d-8fdf-7914ebd26a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 27 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.40.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 40.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.5.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=2923a3c11c2cabfa36ec41ea7d6d6b0ebedd74c37f78541fa02850339747d77e\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.6.0\n",
            "    Uninstalling tensorboard-2.6.0:\n",
            "      Successfully uninstalled tensorboard-2.6.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0\n",
            "    Uninstalling tensorflow-2.6.0:\n",
            "      Successfully uninstalled tensorflow-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting tensorflow_text==1.15\n",
            "  Downloading tensorflow_text-1.15.0-cp37-cp37m-manylinux1_x86_64.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<1.16,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.40.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.37.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.5.0)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-1.15.0\n"
          ]
        }
      ],
      "source": [
        "# Model architecture inspired by Z. Hameed and B. Garcia-Zapirain, \"Sentiment classification using a single-layered BiLSTM model\", IEEE Access, vol. 8, pp. 73992-74001, 2020.\n",
        "!pip install tensorflow==1.15\n",
        "!pip install tensorflow_hub>=0.6.0\n",
        "!pip3 install tensorflow_text==1.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kaqBFk6YOYH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, Input, GlobalMaxPool1D, GlobalAveragePooling1D, concatenate\n",
        "\n",
        "from tensorflow.keras.layers import Lambda\n",
        "\n",
        "def process_text(document):\n",
        "     \n",
        "    # Remove extra white space from text\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "         \n",
        "    # Remove all the special characters from text\n",
        "    document = re.sub(r'\\W', ' ', str(document))\n",
        " \n",
        "    # Word tokenization       \n",
        "    tokens = document.split()\n",
        "        \n",
        "    tokens = [word for word in tokens if len(word) > 2]\n",
        " \n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YHxcsrJhYgna",
        "outputId": "eb431f35-73bd-437a-a644-fe5eca8855ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Statement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joy</td>\n",
              "      <td>Thank you , Steven . I accept your advice .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>surprise</td>\n",
              "      <td>Oh my God, I can't believe I have two-two chil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Look, it's not that big of a deal, so Monica a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>anger</td>\n",
              "      <td>And I wanna know why?!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>joy</td>\n",
              "      <td>And, ah, you know, your fooling around with her.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Emotion                                          Statement\n",
              "0       joy       Thank you , Steven . I accept your advice . \n",
              "1  surprise  Oh my God, I can't believe I have two-two chil...\n",
              "2   neutral  Look, it's not that big of a deal, so Monica a...\n",
              "3     anger                            And I wanna know why?!!\n",
              "4       joy   And, ah, you know, your fooling around with her."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv('LOCAL_PATH_TO_DATASET')\n",
        "df = df[['Emotion','Statement']]\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "88b3PBgiYi5j",
        "outputId": "1de76526-4e7f-4e93-e9d6-750cd2bb4bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Statement</th>\n",
              "      <th>preprocessedStatement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joy</td>\n",
              "      <td>Thank you , Steven . I accept your advice .</td>\n",
              "      <td>[thank, you, steven, accept, your, advice]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>surprise</td>\n",
              "      <td>Oh my God, I can't believe I have two-two chil...</td>\n",
              "      <td>[god, can, believe, have, two, two, children]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Look, it's not that big of a deal, so Monica a...</td>\n",
              "      <td>[look, not, that, big, deal, monica, and, chan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>anger</td>\n",
              "      <td>And I wanna know why?!!</td>\n",
              "      <td>[and, wanna, know, why]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>joy</td>\n",
              "      <td>And, ah, you know, your fooling around with her.</td>\n",
              "      <td>[and, you, know, your, fooling, around, with, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Emotion  ...                              preprocessedStatement\n",
              "0       joy  ...         [thank, you, steven, accept, your, advice]\n",
              "1  surprise  ...      [god, can, believe, have, two, two, children]\n",
              "2   neutral  ...  [look, not, that, big, deal, monica, and, chan...\n",
              "3     anger  ...                            [and, wanna, know, why]\n",
              "4       joy  ...  [and, you, know, your, fooling, around, with, ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tqdm import tqdm \n",
        "\n",
        "df['preprocessedStatement'] = df.Statement.apply(process_text)\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqWg6VICYoCf"
      },
      "outputs": [],
      "source": [
        "max_length = df.preprocessedStatement.apply(lambda x: len(x)).max()\n",
        "\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(df['preprocessedStatement'] )\n",
        "vocab_size = len(t.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT3Bc97_C_IM"
      },
      "outputs": [],
      "source": [
        "new_X = []\n",
        "for seq in df['preprocessedStatement']:\n",
        "    new_seq = []\n",
        "    for i in range(max_length):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(\"PADword\")\n",
        "    new_X.append(new_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41rk75gIZSSm",
        "outputId": "7b757db5-ae63-4e6f-d78c-d0b1b58547d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "# Encode labels in column 'Emotion'. \n",
        "df['Emotion'] = le.fit_transform(df['Emotion']) \n",
        "y = df.pop('Emotion')\n",
        "y_new = tf.keras.utils.to_categorical(y, num_classes=7)\n",
        "print(y_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkROi1RBVOqX"
      },
      "outputs": [],
      "source": [
        "new_X_df = pd.DataFrame(new_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRr9nEFdZ1Ak"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(new_X_df, y_new, test_size=0.04, stratify=y_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eoe5-oVHJD_0"
      },
      "outputs": [],
      "source": [
        "#for meld-dd\n",
        "x_val, y_val = x_train[:174], y_train[:174] \n",
        "x_train, y_train = x_train[174:], y_train[174:]\n",
        "x_val, y_val = x_val[:128], y_val[:128] \n",
        "x_test, y_test = x_test[:1216], y_test[:1216]\n",
        "\n",
        "# #for isear\n",
        "# x_val, y_val = x_train[:143], y_train[:143] \n",
        "# x_train, y_train = x_train[143:], y_train[143:]\n",
        "# x_val, y_val = x_val[:128], y_val[:128] \n",
        "# x_test, y_test = x_test[:288], y_test[:288]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkbsu0vGaCeb"
      },
      "outputs": [],
      "source": [
        "batch_size = 64 #32 for Isear, 64 for Meld-dd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "\n",
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7Bjtb8QaW4-"
      },
      "outputs": [],
      "source": [
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(inputs={\n",
        "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
        "                            \"sequence_len\": tf.constant(batch_size*[max_length])\n",
        "                      },\n",
        "                      signature=\"tokens\",\n",
        "                      as_dict=True)[\"elmo\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCyFxbVvbE3n"
      },
      "outputs": [],
      "source": [
        "def focal_loss(gamma=2., alpha=4.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLTtN8T-adCP",
        "outputId": "08842331-8590-4906-abc2-ea09ceeccfdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(64, 151)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (64, 151, 1024)      0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (64, 151, 128)       557568      lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (64, 128)            0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (64, 128)            0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (64, 256)            0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (64, 128)            32896       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (64, 7)              903         dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 591,367\n",
            "Trainable params: 591,367\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "input_layer = Input(shape=(max_length, ), batch_size = batch_size, dtype=tf.string) \n",
        "embedding = Lambda(ElmoEmbedding, output_shape=(max_length, 1024))(input_layer)\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(embedding) \n",
        "x_a = GlobalMaxPool1D()(x)\n",
        "x_b = GlobalAveragePooling1D()(x)\n",
        "x = concatenate([x_a,x_b])\n",
        "x = Dense(128, activation=\"relu\")(x) \n",
        "x = Dense(7, activation='softmax')(x)\n",
        "model_elmo = Model(inputs=input_layer, outputs=x)\n",
        "model_elmo.compile(loss=focal_loss(alpha=1), optimizer='adam', metrics=['accuracy']) #Alternative: tf.keras.metrics.Recall() as metric \n",
        "model_elmo.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amISgR0LehmP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_elmo,show_shapes= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzSRatiaep30",
        "outputId": "a783c7ec-fc00-4e93-9288-49f78d10ba14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 29696 samples, validate on 128 samples\n",
            "Epoch 1/10\n",
            "29696/29696 [==============================] - 1213s 41ms/sample - loss: 0.7069 - acc: 0.5941 - val_loss: 0.6630 - val_acc: 0.5703\n",
            "Epoch 2/10\n",
            "29696/29696 [==============================] - 1204s 41ms/sample - loss: 0.5979 - acc: 0.6489 - val_loss: 0.6247 - val_acc: 0.6328\n",
            "Epoch 3/10\n",
            "29696/29696 [==============================] - 1211s 41ms/sample - loss: 0.5405 - acc: 0.6776 - val_loss: 0.6354 - val_acc: 0.6406\n",
            "Epoch 4/10\n",
            "29696/29696 [==============================] - 1209s 41ms/sample - loss: 0.4857 - acc: 0.7033 - val_loss: 0.6620 - val_acc: 0.6094\n",
            "Epoch 5/10\n",
            "29696/29696 [==============================] - 1207s 41ms/sample - loss: 0.4217 - acc: 0.7328 - val_loss: 0.6433 - val_acc: 0.6328\n",
            "Epoch 6/10\n",
            "29696/29696 [==============================] - 1213s 41ms/sample - loss: 0.3554 - acc: 0.7639 - val_loss: 0.6649 - val_acc: 0.6484\n",
            "Epoch 7/10\n",
            "29696/29696 [==============================] - 1226s 41ms/sample - loss: 0.2906 - acc: 0.7986 - val_loss: 0.7350 - val_acc: 0.6094\n",
            "Epoch 8/10\n",
            "29696/29696 [==============================] - 1218s 41ms/sample - loss: 0.2408 - acc: 0.8272 - val_loss: 0.7412 - val_acc: 0.6328\n",
            "Epoch 9/10\n",
            "29696/29696 [==============================] - 1218s 41ms/sample - loss: 0.1996 - acc: 0.8536 - val_loss: 0.8345 - val_acc: 0.5938\n",
            "Epoch 10/10\n",
            "29696/29696 [==============================] - 1216s 41ms/sample - loss: 0.1685 - acc: 0.8746 - val_loss: 0.8446 - val_acc: 0.6484\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd580ca4210>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_elmo.fit(x_train, y_train, epochs = 10, callbacks=[callback], validation_data=(x_val, y_val)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOTxMgJ0VxmB"
      },
      "outputs": [],
      "source": [
        "y_pred = model_elmo.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj_qCv7fVyn9"
      },
      "outputs": [],
      "source": [
        "y_pred_clean = np.argmax(y_pred, 1)\n",
        "y_test_clean = np.argmax(y_test, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKfMbLMPV2O9",
        "outputId": "4d56d0b2-bfc5-4bf7-ebcf-4ed35501ad0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.40      0.44       103\n",
            "           1       0.32      0.28      0.30        29\n",
            "           2       0.67      0.20      0.31        20\n",
            "           3       0.76      0.84      0.80       596\n",
            "           4       0.50      0.47      0.48       249\n",
            "           5       0.42      0.44      0.43        85\n",
            "           6       0.58      0.49      0.53       134\n",
            "\n",
            "    accuracy                           0.64      1216\n",
            "   macro avg       0.53      0.45      0.47      1216\n",
            "weighted avg       0.63      0.64      0.63      1216\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_clean, y_pred_clean))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BiLSTM-Elmo-True.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
